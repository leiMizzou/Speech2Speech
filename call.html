<!DOCTYPE html>
<html>
<head>
    <meta charset="UTF-8">
    <title>语音问诊（带会话记忆示例）</title>
    <style>
        body { margin: 0; font-family: system-ui; }
        .container { max-width: 800px; margin: 0 auto; height: 100vh; display: flex; }
        
        .status-panel {
            width: 300px;
            background: #1f2937;
            color: #e5e7eb;
            padding: 1rem;
            overflow-y: auto;
            font-family: monospace;
        }
        .status-item {
            margin: 0.5rem 0;
            padding: 0.5rem;
            border-left: 3px solid;
            font-size: 14px;
        }
        .status-info { border-color: #3b82f6; }
        .status-success { border-color: #10b981; }
        .status-error { border-color: #ef4444; }
        
        .main-container {
            flex: 1;
            display: flex;
            flex-direction: column;
        }
        
        .header { 
            background: #2563eb; 
            color: white; 
            padding: 1rem; 
            display: flex; 
            align-items: center; 
            justify-content: space-between; 
        }
        .doctor-info { display: flex; align-items: center; gap: 1rem; }
        .avatar { 
            width: 40px; 
            height: 40px; 
            background: #3b82f6; 
            border-radius: 50%; 
            display: flex; 
            align-items: center; 
            justify-content: center; 
        }
        .call-status { display: flex; align-items: center; gap: 0.5rem; }
        .status-dot { 
            width: 8px; 
            height: 8px; 
            background: #4ade80; 
            border-radius: 50%; 
        }
        .chat-container { 
            flex: 1; 
            overflow-y: auto; 
            padding: 1rem; 
            background: #f9fafb; 
        }
        .message { 
            margin: 0.5rem 0; 
            max-width: 80%; 
            padding: 0.75rem; 
            border-radius: 0.5rem; 
        }
        .user-message { 
            margin-left: auto; 
            background: #2563eb; 
            color: white; 
        }
        .bot-message { 
            background: white; 
            box-shadow: 0 1px 3px rgba(0,0,0,0.1); 
        }
        .system-message { 
            text-align: center; 
            background: #e5e7eb; 
            color: #4b5563; 
            width: 100%; 
        }
        .controls { 
            padding: 1rem; 
            background: white; 
            display: flex; 
            justify-content: center; 
            gap: 2rem; 
            border-top: 1px solid #e5e7eb; 
        }
        .btn { 
            padding: 1rem; 
            border-radius: 50%; 
            border: none; 
            cursor: pointer; 
            font-size: 1.5rem;
        }
        .btn-mute { background: #f3f4f6; color: #4b5563; }
        .btn-mute.active { background: #fee2e2; color: #ef4444; }
        .btn-call { background: #22c55e; color: white; }
        .btn-call.active { background: #ef4444; }
        .btn-interrupt { background: #f59e0b; color: white; }
        .btn-interrupt.disabled { background: #fcd34d; cursor: not-allowed; }
        .resource { 
            margin-top: 0.5rem; 
            padding: 0.5rem; 
            background: #eff6ff; 
            border-radius: 0.25rem; 
            font-size: 0.875rem; 
        }
        .timestamp { 
            font-size: 0.75rem; 
            opacity: 0.7; 
            margin-top: 0.25rem; 
        }
        @keyframes pulse { 
            0%, 100% { opacity: 1; }
            50% { opacity: 0.3; }
        }
        .pulse { 
            animation: pulse 2s cubic-bezier(0.4, 0, 0.6, 1) infinite; 
        }
    </style>
</head>
<body>
    <div class="container">
        <!-- 状态日志面板（调试信息） -->
        <div id="statusPanel" class="status-panel">
            <h3>调试信息</h3>
            <div id="statusLogs"></div>
        </div>
        
        <!-- 主体区域 -->
        <div class="main-container">
            <div class="header">
                <div class="doctor-info">
                    <div class="avatar">王</div>
                    <div>
                        <h2 style="margin: 0">王医生</h2>
                        <p style="margin: 0; font-size: 0.875rem; opacity: 0.8">ABC医院 心理咨询师</p>
                    </div>
                </div>
                <div class="call-status" style="display: none">
                    <div class="status-dot pulse"></div>
                    <span>通话中</span>
                </div>
            </div>
            <div id="chatContainer" class="chat-container"></div>
            <div class="controls">
                <button id="muteBtn" class="btn btn-mute" title="静音/取消静音">🎤</button>
                <button id="callBtn" class="btn btn-call" title="开始/结束通话">📞</button>
                <button id="interruptBtn" class="btn btn-interrupt disabled" title="打断播放" disabled>⏹️</button>
            </div>
        </div>
    </div>

    <!-- 音频处理器工作线程代码 -->
    <script type="text/worklet" id="audioWorkletScript">
        class AudioProcessor extends AudioWorkletProcessor {
            constructor() {
                super();
                this.bufferSize = 2048;
                this.buffer = new Float32Array(this.bufferSize);
                this.bufferIndex = 0;
                this.sampleRate = 16000;
            }

            process(inputs, outputs, parameters) {
                const input = inputs[0][0];
                if (!input) return true;

                for (let i = 0; i < input.length; i++) {
                    this.buffer[this.bufferIndex] = input[i];
                    this.bufferIndex++;

                    if (this.bufferIndex >= this.bufferSize) {
                        const intData = new Int16Array(this.bufferSize);
                        for (let j = 0; j < this.bufferSize; j++) {
                            intData[j] = Math.max(-32768, Math.min(32767, this.buffer[j] * 32768));
                        }
                        this.port.postMessage(intData.buffer, [intData.buffer]);
                        this.bufferIndex = 0;
                        this.buffer = new Float32Array(this.bufferSize);
                    }
                }

                return true;
            }
        }

        registerProcessor('audio-processor', AudioProcessor);
    </script>

    <script>
        //================== 全局状态 & 变量 ==================//

        // 保存最多 10 轮的对话（用户+AI 一轮），即最大 20 条消息
        // 结构示例：[{ role: 'user', content: '...' }, { role: 'assistant', content: '...' }, ...]
        let conversationMemory = [];

        // 用来跟踪通话状态
        let isCallActive = false;
        let isMuted = false;
        let ws = null;
        let audioStream = null;
        let audioContext = null; // 用于录音
        let audioWorkletNode = null;

        // 用于播放 TTS 的全局 AudioContext（避免频繁创建/关闭）
        let globalAudioContext = null;

        // 当前正在播放的 TTS 来源
        let currentTTSSource = null;
        let currentTTSContext = null;

        // 用于合并短暂停顿导致的多次 "2pass-offline" 识别结果
        let pendingText = "";
        let finalTimer = null;
        const WAIT_MS = 1000; // 等待 1秒

        // DOM元素
        const chatContainer = document.getElementById('chatContainer');
        const callBtn = document.getElementById('callBtn');
        const muteBtn = document.getElementById('muteBtn');
        const interruptBtn = document.getElementById('interruptBtn');
        const callStatus = document.querySelector('.call-status');
        const statusLogs = document.getElementById('statusLogs');

        //================== 日志 & UI 辅助函数 ==================//

        function addStatusLog(message, type = 'info') {
            const timestamp = new Date().toLocaleTimeString();
            const div = document.createElement('div');
            div.className = `status-item status-${type}`;
            div.innerHTML = `[${timestamp}] ${message}`;
            statusLogs.appendChild(div);
            statusLogs.scrollTop = statusLogs.scrollHeight;
        }

        function addMessage(content, type = 'system', resources = []) {
            const div = document.createElement('div');
            div.className = `message ${type}-message`;
            div.innerHTML = `
                <div>${content}</div>
                ${resources.map(r => `
                    <div class="resource">
                        <div><strong>${r.title}</strong></div>
                        <div>${r.summary}</div>
                        <div style="font-size: 0.75rem; color: #6b7280">
                            相关度: ${(r.rerank_score * 100).toFixed(0)}%
                        </div>
                    </div>
                `).join('')}
                <div class="timestamp">${new Date().toLocaleTimeString()}</div>
            `;
            chatContainer.appendChild(div);
            chatContainer.scrollTop = chatContainer.scrollHeight;
        }

        //================== 与AI交互 & TTS 播放 ==================//

        // 构造对话上下文（包含 system 提示 + 最近 10 轮对话 + 当前用户问题）
        function buildMessagesForAPI(userInput) {
            // 1. 系统消息
            const systemMessage = {
                role: "system",
                content: "你是ABC医院王医生，请针对患者或患者家属的提问给出合适的回复。回复要言简意赅，控制在100字以内。"
            };

            // 2. 取 conversationMemory 中最多 10 轮的消息
            // 如果大于 20 条消息，就取后 20 条
            const startIndex = conversationMemory.length > 20 ? conversationMemory.length - 20 : 0;
            const trimmedMemory = conversationMemory.slice(startIndex);

            // 3. 当前用户问题
            const userMessage = {
                role: "user",
                content: userInput
            };

            // 最终 messages
            return [systemMessage, ...trimmedMemory, userMessage];
        }

        // 更新对话记忆数组
        // 如果超出 10 轮，则丢弃最早的一轮（2 条消息）
        function updateConversationMemory(role, content) {
            // 推入新的消息
            conversationMemory.push({ role, content });

            // 如果超过 20 条消息（10 轮），则移除最早的 2 条
            while (conversationMemory.length > 20) {
                conversationMemory.shift(); // 移除最早的一条
            }
        }

        // 获取 AI 回复
        async function getAIResponse(userInput) {
            addStatusLog('正在获取AI回复...', 'info');

            // 先把用户输入存入记忆
            // 这里不立即 push，因为 handleASRFinalResult 中已经执行了：updateConversationMemory("user", userInput)
            // 如果你希望先把 userInput 存储，然后再组合请求，也可在 handleASRFinalResult 调用此处时修改逻辑

            try {
                // 构造 messages
                const messages = buildMessagesForAPI(userInput);

                const response = await fetch('https://api.deepseek.com/v1/chat/completions', {
                    method: 'POST',
                    headers: {
                        'Content-Type': 'application/json',
                        'Authorization': 'Bearer sk-38ad42271d60445f93b92dfa4df3e4c5'
                    },
                    body: JSON.stringify({
                        model: "deepseek-chat",
                        messages: messages,
                        max_tokens: 400
                    })
                });
                const data = await response.json();
                addStatusLog('AI回复成功', 'success');

                // 如果 AI 没有正常返回，则给一个默认提示
                const aiText = data.choices && data.choices[0] 
                               ? data.choices[0].message.content 
                               : "抱歉，我现在无法回应。";

                // 存储 AI 回复到对话记忆
                updateConversationMemory("assistant", aiText);

                return {
                    content: aiText,
                    resources: await getRecommendations(userInput)
                };
            } catch (error) {
                addStatusLog(`AI响应错误: ${error.message}`, 'error');
                return {
                    content: "抱歉，我现在无法回应，请稍后再试。",
                    resources: []
                };
            }
        }

        // 获取相关资源推荐（示例）
        async function getRecommendations(text) {
            addStatusLog('正在获取推荐资源...', 'info');
            const triggers = ['抑郁', '焦虑', '睡眠', '压力'];
            if (triggers.some(trigger => text.includes(trigger))) {
                addStatusLog('找到相关推荐资源', 'success');
                return [{
                    title: "心理健康自助指南",
                    summary: "提供实用的心理健康管理建议和技巧",
                    rerank_score: 0.85
                }];
            }
            addStatusLog('未找到相关推荐资源', 'info');
            return [];
        }

        // 播放 TTS 语音
        async function playTTS(text) {
            addStatusLog('正在转换语音...', 'info');
            try {
                // 保存麦克风的当前状态
                const wasMutedBefore = isMuted;
                if (!wasMutedBefore && audioStream) {
                    isMuted = true;
                    audioStream.getAudioTracks().forEach(track => {
                        track.enabled = false;
                    });
                    muteBtn.classList.add('active');
                    muteBtn.textContent = '🔇';
                    addStatusLog('播放语音时自动静音麦克风', 'info');
                }

                // 如果全局 AudioContext 尚未创建，则创建
                if (!globalAudioContext) {
                    globalAudioContext = new (window.AudioContext || window.webkitAudioContext)({
                        sampleRate: 16000
                    });
                }

                // 请求 TTS 音频（请自行修改 TTS 服务地址）
                const encodedText = encodeURIComponent(text);
                const ttsUrl = `http://192.168.8.16:9880/?text=${encodedText}&text_language=zh`;

                const response = await fetch(ttsUrl, { method: 'GET' });
                if (!response.ok) {
                    throw new Error(`TTS 请求失败，状态码: ${response.status}`);
                }

                const audioData = await response.arrayBuffer();
                const audioBuffer = await globalAudioContext.decodeAudioData(audioData);
                const source = globalAudioContext.createBufferSource();
                source.buffer = audioBuffer;

                // 创建增益节点以支持淡出
                const gainNode = globalAudioContext.createGain();
                gainNode.gain.setValueAtTime(1, globalAudioContext.currentTime);
                source.connect(gainNode).connect(globalAudioContext.destination);

                // 监听播放结束事件
                source.onended = () => {
                    addStatusLog('语音播放结束', 'info');
                    // 恢复麦克风状态
                    if (!wasMutedBefore && audioStream) {
                        isMuted = false;
                        audioStream.getAudioTracks().forEach(track => {
                            track.enabled = true;
                        });
                        muteBtn.classList.remove('active');
                        muteBtn.textContent = '🎤';
                        addStatusLog('恢复麦克风状态', 'info');
                    }
                    // 清除 TTS 播放状态
                    currentTTSSource = null;
                    currentTTSContext = null;
                    // 禁用打断按钮
                    interruptBtn.disabled = true;
                    interruptBtn.classList.add('disabled');
                };

                // 开始播放
                source.start(0);
                addStatusLog('语音播放成功', 'success');

                // 记录 TTS 播放状态
                currentTTSSource = source;
                currentTTSContext = globalAudioContext;

                // 启用打断按钮
                interruptBtn.disabled = false;
                interruptBtn.classList.remove('disabled');

            } catch (error) {
                addStatusLog(`TTS播放错误: ${error.message}`, 'error');
                // 如果在播放过程中发生错误，确保恢复麦克风状态
                if (isMuted && !muteBtn.classList.contains('active') && audioStream) {
                    isMuted = false;
                    audioStream.getAudioTracks().forEach(track => {
                        track.enabled = true;
                    });
                    muteBtn.classList.remove('active');
                    muteBtn.textContent = '🎤';
                    addStatusLog('恢复麦克风状态', 'info');
                }
            }
        }

        //================== 优化后的中断 TTS 函数 ==================//
        async function interruptTTS() {
            if (currentTTSSource && currentTTSContext) {
                addStatusLog('正在中断 TTS 播放...', 'info');

                try {
                    // 断开音源
                    currentTTSSource.disconnect();
                    addStatusLog('音频源已断开连接', 'info');

                    // 创建一个增益节点执行快速淡出
                    const gainNode = currentTTSContext.createGain();
                    currentTTSSource.connect(gainNode).connect(currentTTSContext.destination);
                    gainNode.gain.setValueAtTime(gainNode.gain.value, currentTTSContext.currentTime);
                    // 50ms淡出
                    gainNode.gain.exponentialRampToValueAtTime(0.00001, currentTTSContext.currentTime + 0.05);

                    // 50ms后停止音源，再延迟恢复麦克风
                    setTimeout(() => {
                        try {
                            currentTTSSource.stop(0);
                            addStatusLog('音频源已停止播放', 'info');
                        } catch (err) {
                            addStatusLog(`停止音源时发生错误: ${err.message}`, 'error');
                        }

                        // 不关闭 globalAudioContext

                        // 清理引用
                        currentTTSSource = null;
                        currentTTSContext = null;

                        // 再加一点延迟恢复麦克风
                        setTimeout(() => {
                            if (isMuted && audioStream) {
                                isMuted = false;
                                audioStream.getAudioTracks().forEach(track => {
                                    track.enabled = true;
                                });
                                muteBtn.classList.remove('active');
                                muteBtn.textContent = '🎤';
                                addStatusLog('恢复麦克风状态', 'info');
                            }

                            // 更新 UI
                            interruptBtn.disabled = true;
                            interruptBtn.classList.add('disabled');
                            addMessage('语音播放已中断，您可以继续咨询', 'system');
                        }, 100);
                    }, 50);
                } catch (error) {
                    addStatusLog(`中断 TTS 播放失败: ${error.message}`, 'error');
                }
            } else {
                // 当前没有TTS在播放，也要确保麦克风恢复
                if (isMuted && audioStream) {
                    isMuted = false;
                    audioStream.getAudioTracks().forEach(track => {
                        track.enabled = true;
                    });
                    muteBtn.classList.remove('active');
                    muteBtn.textContent = '🎤';
                    addStatusLog('恢复麦克风状态', 'info');
                }
                interruptBtn.disabled = true;
                interruptBtn.classList.add('disabled');
                addMessage('当前没有正在播放的语音', 'system');
            }
        }

        //================== WebSocket & 识别结果处理 ==================//

        // 把一次完整的话语合并后发送给AI并播放TTS
        async function handleASRFinalResult(text) {
            // 将用户说的话存入 conversationMemory
            // （注意：如果您想在 AI 回复后再统一管理，也可根据需求自行调整逻辑）
            updateConversationMemory("user", text);

            // 先合并到 pendingText
            pendingText = pendingText ? (pendingText + " " + text) : text;
            addStatusLog(`识别到最终文本: ${text}`, 'info');

            // 如果有尚未触发的定时器，先清除
            if (finalTimer) {
                clearTimeout(finalTimer);
                finalTimer = null;
            }

            // 重设一个定时器，1秒后触发
            finalTimer = setTimeout(async () => {
                // 认为用户说话结束
                const userInput = pendingText.trim();
                addMessage(userInput, 'user'); // 在页面中显示用户文本

                // 请求AI并播放TTS
                const aiResponse = await getAIResponse(userInput);
                await playTTS(aiResponse.content);
                addMessage(aiResponse.content, 'bot', aiResponse.resources);

                // 清空合并缓冲
                pendingText = "";
                finalTimer = null;
            }, WAIT_MS);
        }

        //================== 通话控制逻辑 ==================//

        async function startCall() {
            try {
                addStatusLog('正在请求麦克风权限...', 'info');
                audioStream = await navigator.mediaDevices.getUserMedia({ 
                    audio: {
                        channelCount: 1,
                        sampleRate: 16000
                    } 
                });
                addStatusLog('麦克风权限获取成功', 'success');

                // 创建录音用 AudioContext
                audioContext = new (window.AudioContext || window.webkitAudioContext)({
                    sampleRate: 16000
                });

                // 加载 AudioWorklet
                const audioWorkletSource = document.getElementById('audioWorkletScript').textContent;
                const workletBlob = new Blob([audioWorkletSource], { type: 'text/javascript' });
                const workletUrl = URL.createObjectURL(workletBlob);
                await audioContext.audioWorklet.addModule(workletUrl);

                // 建立 WebSocket 连接
                const wsUrl = 'wss://192.168.8.167:10096';
                ws = new WebSocket(wsUrl);

                ws.onopen = async () => {
                    addStatusLog('WebSocket连接成功', 'success');
                    // 发送 ASR 配置
                    const config = {
                        mode: "2pass",
                        chunk_size: [5, 10, 5],
                        chunk_interval: 10,
                        wav_name: "microphone",
                        is_speaking: true,
                        hotwords: "",
                        itn: true
                    };
                    ws.send(JSON.stringify(config));
                    addStatusLog('已发送ASR配置信息', 'info');

                    // 连接到AudioWorklet
                    const source = audioContext.createMediaStreamSource(audioStream);
                    audioWorkletNode = new AudioWorkletNode(audioContext, 'audio-processor');
                    audioWorkletNode.port.onmessage = (event) => {
                        if (isCallActive && !isMuted && ws.readyState === WebSocket.OPEN) {
                            ws.send(event.data);
                        }
                    };
                    source.connect(audioWorkletNode);

                    addStatusLog('开始录音', 'success');
                };

                ws.onerror = (error) => {
                    addStatusLog(`WebSocket错误: ${error}`, 'error');
                };

                ws.onclose = () => {
                    addStatusLog('WebSocket连接已关闭', 'info');
                    endCall();
                };

                ws.onmessage = async (event) => {
                    try {
                        const data = JSON.parse(event.data);
                        if (data.text && data.mode === "2pass-offline") {
                            handleASRFinalResult(data.text);
                        }
                    } catch (error) {
                        addStatusLog(`处理消息错误: ${error.message}`, 'error');
                    }
                };

                isCallActive = true;
                callBtn.classList.add('active');
                callStatus.style.display = 'flex';
                addMessage('通话已开始，您可以开始咨询');
            } catch (error) {
                addStatusLog(`启动通话错误: ${error.message}`, 'error');
                addMessage('启动通话失败，请检查麦克风权限');
            }
        }

        async function endCall() {
            if (!isCallActive) {
                return;
            }
            addStatusLog('正在结束通话...', 'info');
            isCallActive = false;

            // 关闭 WebSocket
            if (ws) {
                ws.close();
                addStatusLog('WebSocket已关闭', 'info');
                ws = null;
            }
            
            // 断开音频处理器
            if (audioWorkletNode) {
                audioWorkletNode.disconnect();
                addStatusLog('音频处理器已断开', 'info');
                audioWorkletNode = null;
            }
            
            // 关闭录音的 AudioContext
            if (audioContext) {
                try {
                    if (audioContext.state !== 'closed') {
                        await audioContext.close();
                        addStatusLog('捕获用AudioContext已关闭', 'info');
                    }
                } catch (error) {
                    addStatusLog(`关闭AudioContext失败: ${error.message}`, 'error');
                }
                audioContext = null;
            }
            
            // 停止音频流
            if (audioStream) {
                audioStream.getTracks().forEach(track => track.stop());
                addStatusLog('音频流已关闭', 'info');
                audioStream = null;
            }

            // 如果有尚未处理的合并文本，直接清空
            if (pendingText) {
                pendingText = "";
            }
            if (finalTimer) {
                clearTimeout(finalTimer);
                finalTimer = null;
            }

            // 如果有 TTS 正在播放，强制中断
            if (currentTTSSource) {
                interruptTTS();
            }

            // 更新 UI
            callBtn.classList.remove('active');
            callStatus.style.display = 'none';
            addMessage('通话已结束');
            addStatusLog('通话结束完成', 'success');
        }

        //================== 按钮事件绑定 ==================//

        callBtn.onclick = () => {
            if (!isCallActive) {
                startCall();
            } else {
                endCall();
            }
        };

        muteBtn.onclick = () => {
            if (audioStream) {
                isMuted = !isMuted;
                audioStream.getAudioTracks().forEach(track => {
                    track.enabled = !isMuted;
                });
                muteBtn.classList.toggle('active', isMuted);
                muteBtn.textContent = isMuted ? '🔇' : '🎤';
                addStatusLog(`麦克风已${isMuted ? '静音' : '取消静音'}`, 'info');
            }
        };

        interruptBtn.onclick = () => {
            if (!interruptBtn.disabled) {
                interruptTTS();
            }
        };

        //================== 页面加载/卸载处理 ==================//

        window.onload = async () => {
            addStatusLog('页面初始化开始', 'info');
            
            // 简要功能检查
            if (!navigator.mediaDevices || !navigator.mediaDevices.getUserMedia) {
                addStatusLog('您的浏览器不支持音频输入 (getUserMedia)', 'error');
                return;
            }
            if (!window.WebSocket) {
                addStatusLog('您的浏览器不支持WebSocket', 'error');
                return;
            }
            if (!window.AudioContext && !window.webkitAudioContext) {
                addStatusLog('您的浏览器不支持Web Audio API', 'error');
                return;
            }

            // 快速检查 AudioWorklet
            let tempContext;
            try {
                tempContext = new (window.AudioContext || window.webkitAudioContext)();
                if (!tempContext.audioWorklet) {
                    addStatusLog('您的浏览器不支持AudioWorklet', 'error');
                    tempContext.close();
                    return;
                }
                tempContext.close();
            } catch (err) {
                addStatusLog(`音频上下文初始化失败: ${err.message}`, 'error');
                return;
            }
            
            addStatusLog('浏览器功能检查完成', 'success');
            addStatusLog('页面初始化完成', 'success');
            addMessage('系统就绪，点击通话按钮开始咨询');
        };

        window.onbeforeunload = () => {
            if (isCallActive) {
                endCall();
            }
        };
    </script>
</body>
</html>
